backend
- errors 
- page rank
- crawling from top domains and distributing that

devops:
- kubernetes
- redis
- elasticsearch
- distributing nodes 
- server stuff
- continuous development?

misc:
- mobile port
- ai?
- suggestions 
- other types of content like images
- text summary + rake from scratch after?
- GET RID OF DATA.JSON WHEN DEVOPS

- make results better, change elasticsearch weights if necessary, fuzziness?
- set can't be processed error?
- elasticsearch nytimes not coming
- check scraping errors
- yahoo.com scraping error?
- page rank?
- devops, remember everything before you start

devops todo:
- containerize applications using docker or something?
- service for static ip
- volume for db storage
- have multiple deployments in case crash during scraping 
- stateful set for elasticsearch, hard to do, external?
- robust
-  how to distribute computing, hash all links then distribute to kubernetes nodes?, change url format and get rid of numbers too
- have to containerize the different parts of app into separate microservice images then upload to kubernetes? 
- how to open ports in client and server to internet?
- elasticsearch deployment, redis deployment, server and client deployments?
- specify ports in yaml file to connect client and server?
- or just dockerize the whole react and nodejs app as one image? DOCKER COMPOSE?

- DOCKER COMPOSE, get elasticsearch and redis images, client image, server image then compose 
- KUBERNETES: four docker images: elasticsearch, redis, client, server
    - client will run on ip open to internet, make requests to server port
    - export server port, listen for requests from client on that port 
    - elasticsearch has default port, when creating server create using that port
    - redis has default port, when creating server create using that port 
    - have separate csv files for urls in each node?
    general: load balancer?, HAVE MULTIPLE PODS FOR scraping/server BUT ONLY ONE FOR EVERYTHING ELSE, SEPARATE SCRAPING AND SERVER SO U CAN REPLICATE SCRAPING ON MANY PODS(set yaml replicas value to 2/3)
- first do kubernetes locally first on one node/multiple? then move to gcp
- steps:
    - make elasticsearch deployment, using docker image, 1 replica
        - elasticsearch INTERNAL service to connect to other stuff
    - make redis deployment, docker image, 1 replica
        - redis INTERNAL service
    - make client deployment, create docker image, 1 replica
        - client EXTERNAL SERVICE 
    - make nodejs deployment, create docker image, 1 replica  --> make separate docker images and deployments for scraping and querying
        - server INTERNAL SERVICE
    - USE INGRESS AFTER INSTEAD OF EXTERNAL SERVICE
    - pick from domain list then remove that line, that's how u can distribute computing?
    - fix error for repeat first domain